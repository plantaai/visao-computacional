{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74b09bd",
   "metadata": {},
   "source": [
    "*no terminal (prompt do comando) do VS Code*:  \n",
    "py -3.10 -m venv .venv-deteccao  \n",
    ".venv-deteccao\\Scripts\\activate\n",
    "> pip install ipykernel jupyter  \n",
    "> pip install -U ultralytics  \n",
    "> pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio  \n",
    "> pip install pillow pyyaml numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e800f",
   "metadata": {},
   "source": [
    "Para fazer os labels: \n",
    "\n",
    "> pip install -U label-studio  \n",
    "> label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc09a92",
   "metadata": {},
   "source": [
    "ETAPA 1 — Separar dataset em train e val (com prints e visualização)  \n",
    "Esta célula procura imagens/labels \"soltos\" em data/yolo/images e data/yolo/labels  \n",
    "(fora das pastas train/val) e faz o split 80/20 por padrão.  \n",
    "Se já houver train/val preenchidos, a célula apenas reporta e não redivide.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, shutil\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from typing import List, Dict, Tuple\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "BASE_DIR = Path(\"../data/yolo\")  # ajuste para o seu caminho (ex.: r\"C:\\Users\\Everaldo\\...\\data\\yolo\")\n",
    "VAL_FRACTION = 0.2\n",
    "SEED = 42\n",
    "MOVE_FILES = False     # True = move; False = copia\n",
    "CREATE_EMPTY_LABELS = True   # cria .txt vazio quando não existir\n",
    "AUTO_RENAME_ON_DUPLICATES = False  # se True, renomeia arquivos com mesmo 'stem' antes de dividir\n",
    "# --------------------------------------------\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "IMAGES_DIR = BASE_DIR / \"images\"\n",
    "LABELS_DIR = BASE_DIR / \"labels\"\n",
    "TRAIN_IM_DIR = IMAGES_DIR / \"train\"\n",
    "VAL_IM_DIR   = IMAGES_DIR / \"val\"\n",
    "TRAIN_LB_DIR = LABELS_DIR / \"train\"\n",
    "VAL_LB_DIR   = LABELS_DIR / \"val\"\n",
    "\n",
    "for d in [IMAGES_DIR, LABELS_DIR, TRAIN_IM_DIR, VAL_IM_DIR, TRAIN_LB_DIR, VAL_LB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def is_split_path(p: Path) -> bool:\n",
    "    parts = {x.lower() for x in p.parts}\n",
    "    return (\"train\" in parts) or (\"val\" in parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1774be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Coletar imagens/labels \"soltos\" (não dentro de train/val)\n",
    "img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "all_imgs = [Path(p) for p in glob(str(IMAGES_DIR / \"**\" / \"*\"), recursive=True) if Path(p).suffix.lower() in img_exts]\n",
    "all_lbls = [Path(p) for p in glob(str(LABELS_DIR / \"**\" / \"*.txt\"), recursive=True)]\n",
    "\n",
    "unsplit_imgs = [p for p in all_imgs if not is_split_path(p)]\n",
    "unsplit_lbls = [p for p in all_lbls if not is_split_path(p)]\n",
    "\n",
    "print(\"=== Caminhos base ===\")\n",
    "print(\"BASE_DIR  :\", BASE_DIR.resolve())\n",
    "print(\"IMAGES_DIR:\", IMAGES_DIR.resolve())\n",
    "print(\"LABELS_DIR:\", LABELS_DIR.resolve())\n",
    "\n",
    "print(\"\\n=== Arquivos encontrados (fora de train/val) ===\")\n",
    "print(\"Imagens  :\", len(unsplit_imgs))\n",
    "print(\"Labels   :\", len(unsplit_lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Mapear por stem e checar duplicatas\n",
    "def map_by_stem(paths: List[Path]) -> Dict[str, List[Path]]:\n",
    "    d: Dict[str, List[Path]] = {}\n",
    "    for p in paths:\n",
    "        d.setdefault(p.stem, []).append(p)\n",
    "    return d\n",
    "\n",
    "imgs_by_stem = map_by_stem(unsplit_imgs)\n",
    "lbls_by_stem = map_by_stem(unsplit_lbls)\n",
    "\n",
    "dup_imgs = {k: v for k, v in imgs_by_stem.items() if len(v) > 1}\n",
    "dup_lbls = {k: v for k, v in lbls_by_stem.items() if len(v) > 1}\n",
    "\n",
    "if dup_imgs or dup_lbls:\n",
    "    print(\"\\n[ALERTA] Foram detectados nomes duplicados (stems repetidos).\")\n",
    "    print(\"Imagens duplicadas:\", len(dup_imgs), \"| Labels duplicados:\", len(dup_lbls))\n",
    "    example_key = next(iter(dup_imgs.keys() if dup_imgs else dup_lbls.keys()), None)\n",
    "    if example_key:\n",
    "        print(\"Exemplo de duplicata:\", example_key, \"→\")\n",
    "        print(\"  imgs:\", [str(p) for p in imgs_by_stem.get(example_key, [])])\n",
    "        print(\"  lbls:\", [str(p) for p in lbls_by_stem.get(example_key, [])])\n",
    "    if not AUTO_RENAME_ON_DUPLICATES:\n",
    "        print(\"\\n[ERRO] Existem duplicatas e AUTO_RENAME_ON_DUPLICATES=False. \"\n",
    "              \"Renomeie manualmente ou ative AUTO_RENAME_ON_DUPLICATES=True e rode novamente.\")\n",
    "        # aborta antes de mexer\n",
    "        raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff10237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) (Opcional) renomear duplicatas automaticamente\n",
    "def safe_rename(path: Path, suffix: str) -> Path:\n",
    "    new_name = f\"{path.stem}_{suffix}{path.suffix}\"\n",
    "    new_path = path.with_name(new_name)\n",
    "    i = 1\n",
    "    while new_path.exists():\n",
    "        new_path = path.with_name(f\"{path.stem}_{suffix}_{i}{path.suffix}\")\n",
    "        i += 1\n",
    "    path.rename(new_path)\n",
    "    return new_path\n",
    "\n",
    "if AUTO_RENAME_ON_DUPLICATES:\n",
    "    print(\"\\n[INFO] Renomeando duplicatas...\")\n",
    "    for k, paths in dup_imgs.items():\n",
    "        for idx, p in enumerate(paths[1:], start=2):  # mantém o primeiro, renomeia do segundo em diante\n",
    "            new_img = safe_rename(p, f\"d{idx}\")\n",
    "            # renomeia o label correspondente se existir\n",
    "            lbl_p = (p.parent.parent.parent / \"labels\" / p.relative_to(IMAGES_DIR).with_suffix(\".txt\")).resolve()\n",
    "            # O caminho acima tenta encontrar um label com mesma estrutura relativa.\n",
    "            # Se não existir nessa estrutura, tenta por nome em unsplit_lbls.\n",
    "            if lbl_p.exists():\n",
    "                _ = safe_rename(lbl_p, f\"d{idx}\")\n",
    "    # recomputa mapas após renomear\n",
    "    all_imgs = [Path(p) for p in glob(str(IMAGES_DIR / \"**\" / \"*\"), recursive=True) if Path(p).suffix.lower() in img_exts]\n",
    "    all_lbls = [Path(p) for p in glob(str(LABELS_DIR / \"**\" / \"*.txt\"), recursive=True)]\n",
    "    unsplit_imgs = [p for p in all_imgs if not is_split_path(p)]\n",
    "    unsplit_lbls = [p for p in all_lbls if not is_split_path(p)]\n",
    "    imgs_by_stem = map_by_stem(unsplit_imgs)\n",
    "    lbls_by_stem = map_by_stem(unsplit_lbls)\n",
    "    print(\"[OK] Duplicatas tratadas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Criar pares (imagem -> label) e criar .txt vazio quando não houver\n",
    "pairs: List[Tuple[Path, Path]] = []\n",
    "missing_labels = 0\n",
    "for stem, img_list in imgs_by_stem.items():\n",
    "    img_path = img_list[0]            # após checagem de duplicatas, presume 1 por stem\n",
    "    lbl_list = lbls_by_stem.get(stem, [])\n",
    "    if lbl_list:\n",
    "        lbl_path = lbl_list[0]\n",
    "    else:\n",
    "        lbl_path = LABELS_DIR / f\"{stem}.txt\"\n",
    "        if CREATE_EMPTY_LABELS and not lbl_path.exists():\n",
    "            lbl_path.touch()\n",
    "            missing_labels += 1\n",
    "    pairs.append((img_path, lbl_path))\n",
    "\n",
    "print(\"\\n=== Pareamento imagem→label ===\")\n",
    "print(\"Total de pares:\", len(pairs))\n",
    "print(\"Labels vazios criados:\", missing_labels)\n",
    "# imprime alguns exemplos\n",
    "for p in pairs[:5]:\n",
    "    print(\" -\", p[0].name, \"<->\", p[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Se já existir estrutura train/val preenchida, não refaz split\n",
    "already_has_split = any(TRAIN_IM_DIR.glob(\"*\")) or any(VAL_IM_DIR.glob(\"*\"))\n",
    "if already_has_split:\n",
    "    print(\"\\n[INFO] Pastas train/val já possuem arquivos. Não será feito novo split.\")\n",
    "else:\n",
    "    # 5a) Embaralhar e dividir\n",
    "    stems = list(imgs_by_stem.keys())\n",
    "    random.shuffle(stems)\n",
    "    n_total = len(stems)\n",
    "    n_val = max(1, int(VAL_FRACTION * n_total)) if n_total > 0 else 0\n",
    "    val_set = set(stems[:n_val])\n",
    "\n",
    "    # 5b) Mover/Copiar\n",
    "    def transfer(src: Path, dst: Path, move=True):\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if move:\n",
    "            shutil.move(str(src), str(dst))\n",
    "        else:\n",
    "            shutil.copy2(str(src), str(dst))\n",
    "\n",
    "    moved_train = moved_val = 0\n",
    "    for stem in stems:\n",
    "        img_path = imgs_by_stem[stem][0]\n",
    "        lbl_path = (lbls_by_stem.get(stem, [LABELS_DIR / f\"{stem}.txt\"]))[0]\n",
    "        dst_im = (VAL_IM_DIR if stem in val_set else TRAIN_IM_DIR) / img_path.name\n",
    "        dst_lb = (VAL_LB_DIR if stem in val_set else TRAIN_LB_DIR) / f\"{stem}.txt\"\n",
    "\n",
    "        transfer(img_path, dst_im, move=MOVE_FILES)\n",
    "        transfer(lbl_path, dst_lb, move=MOVE_FILES)\n",
    "        if stem in val_set:\n",
    "            moved_val += 1\n",
    "        else:\n",
    "            moved_train += 1\n",
    "\n",
    "    print(\"\\n=== Split concluído ===\")\n",
    "    print(f\"Total: {n_total} | train: {moved_train} | val: {moved_val}\")\n",
    "    print(f\"Método: {'move' if MOVE_FILES else 'copy'} | VAL_FRACTION={VAL_FRACTION} | seed={SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4af19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Relatório final dos diretórios\n",
    "def count_files(dirp: Path, exts=(\"*\",)):\n",
    "    return sum(1 for _ in dirp.glob(\"|\".join(exts)))\n",
    "\n",
    "train_imgs = [p for p in TRAIN_IM_DIR.glob(\"*\") if p.suffix.lower() in img_exts]\n",
    "val_imgs   = [p for p in VAL_IM_DIR.glob(\"*\") if p.suffix.lower() in img_exts]\n",
    "train_lbls = list(TRAIN_LB_DIR.glob(\"*.txt\"))\n",
    "val_lbls   = list(VAL_LB_DIR.glob(\"*.txt\"))\n",
    "\n",
    "print(\"\\n=== Pós-split: contagens ===\")\n",
    "print(\"images/train:\", len(train_imgs), \" | labels/train:\", len(train_lbls))\n",
    "print(\"images/val  :\", len(val_imgs)  , \" | labels/val  :\", len(val_lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b61a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Visualização: mostra até 2 imagens do train e 2 do val com caixas\n",
    "def load_yolo_labels(label_file: Path):\n",
    "    if not label_file.exists() or label_file.stat().st_size == 0:\n",
    "        return []\n",
    "    out = []\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for ln in f:\n",
    "            parts = ln.strip().split()\n",
    "            if len(parts) != 5: \n",
    "                continue\n",
    "            cls, xc, yc, w, h = parts\n",
    "            out.append((int(cls), float(xc), float(yc), float(w), float(h)))\n",
    "    return out\n",
    "\n",
    "def yolo_to_xyxy(box, W, H):\n",
    "    cls, xc, yc, w, h = box\n",
    "    x_c, y_c = xc*W, yc*H\n",
    "    bw, bh = w*W, h*H\n",
    "    x1, y1 = x_c - bw/2, y_c - bh/2\n",
    "    x2, y2 = x_c + bw/2, y_c + bh/2\n",
    "    return int(cls), max(0,int(x1)), max(0,int(y1)), min(W-1,int(x2)), min(H-1,int(y2))\n",
    "\n",
    "def preview_with_boxes(img_path: Path, split: str):\n",
    "    lbl_path = (TRAIN_LB_DIR if split==\"train\" else VAL_LB_DIR) / f\"{img_path.stem}.txt\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    W, H = img.size\n",
    "    boxes = load_yolo_labels(lbl_path)\n",
    "    # plota uma figura por imagem\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    for b in boxes:\n",
    "        _, x1, y1, x2, y2 = yolo_to_xyxy(b, W, H)\n",
    "        rect = Rectangle((x1, y1), x2-x1, y2-y1, fill=False, linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "    plt.title(f\"{split}: {img_path.name} | {len(boxes)} caixas\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "if len(train_imgs) == 0 and len(val_imgs) == 0:\n",
    "    print(\"\\n[INFO] Sem imagens para visualizar (verifique se os arquivos estão em\", BASE_DIR, \").\")\n",
    "else:\n",
    "    print(\"\\n=== Pré-visualização (até 4 imagens) ===\")\n",
    "    for p in train_imgs[:2]:\n",
    "        preview_with_boxes(p, \"train\")\n",
    "    for p in val_imgs[:2]:\n",
    "        preview_with_boxes(p, \"val\")\n",
    "    print(\"[OK] Visualização pronta (rolar para ver as figuras).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2245e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 5A — Config + checagens\n",
    "\n",
    "import os, sys, platform, json, random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tenta importar PyTorch e Ultralytics\n",
    "import torch\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except Exception as e:\n",
    "    YOLO = None\n",
    "    print(\"Ultralytics não importado. Rode:  %pip install -U ultralytics\")\n",
    "\n",
    "# ----- Caminhos -----\n",
    "ROOT = Path.cwd()\n",
    "DATASET_DIR = Path(\"../data/yolo\")\n",
    "DATA_YAML = DATASET_DIR / \"data.yaml\"\n",
    "IMAGES_DIR = DATASET_DIR / \"images\"\n",
    "LABELS_DIR = DATASET_DIR / \"labels\"\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| SO:\", platform.platform())\n",
    "print(\"Torch :\", torch.__version__, \"| CUDA disponível?:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device escolhido para treino:\", device)\n",
    "\n",
    "# ----- Verifica dataset -----\n",
    "def count_files(p: Path, exts):\n",
    "    return sum(1 for f in p.glob(\"*\") if f.suffix.lower() in exts)\n",
    "\n",
    "img_exts = (\".jpg\",\".jpeg\",\".png\")\n",
    "train_imgs = [p for p in (IMAGES_DIR/\"train\").glob(\"*\") if p.suffix.lower() in img_exts]\n",
    "val_imgs   = [p for p in (IMAGES_DIR/\"val\").glob(\"*\")   if p.suffix.lower() in img_exts]\n",
    "train_lbls = list((LABELS_DIR/\"train\").glob(\"*.txt\"))\n",
    "val_lbls   = list((LABELS_DIR/\"val\").glob(\"*.txt\"))\n",
    "\n",
    "print(\"\\n=== Dataset ===\")\n",
    "print(\"data.yaml existe? \", DATA_YAML.exists(), \"→\", DATA_YAML)\n",
    "print(\"images/train:\", len(train_imgs), \"| labels/train:\", len(train_lbls))\n",
    "print(\"images/val  :\", len(val_imgs)  , \"| labels/val  :\", len(val_lbls))\n",
    "\n",
    "assert DATA_YAML.exists(), \"data.yaml não encontrado.\"\n",
    "assert len(train_imgs) > 0 and len(train_lbls) > 0, \"Sem dados em train.\"\n",
    "assert len(val_imgs)   > 0 and len(val_lbls)   > 0, \"Sem dados em val.\"\n",
    "\n",
    "# Mostra conteúdo do data.yaml\n",
    "import yaml\n",
    "with open(DATA_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "print(\"\\nConteúdo de data.yaml:\")\n",
    "print(json.dumps(cfg, indent=2, ensure_ascii=False))\n",
    "\n",
    "# ----- Visualização de amostras com caixas -----\n",
    "def load_yolo_labels(txt_path: Path):\n",
    "    if not txt_path.exists() or txt_path.stat().st_size == 0:\n",
    "        return []\n",
    "    out = []\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for ln in f:\n",
    "            parts = ln.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                cls, xc, yc, w, h = parts\n",
    "                out.append((int(cls), float(xc), float(yc), float(w), float(h)))\n",
    "    return out\n",
    "\n",
    "def yolo_to_xyxy(box, W, H):\n",
    "    cls, xc, yc, w, h = box\n",
    "    x_c, y_c = xc*W, yc*H\n",
    "    bw, bh = w*W, h*H\n",
    "    x1, y1 = x_c - bw/2, y_c - bh/2\n",
    "    x2, y2 = x_c + bw/2, y_c + bh/2\n",
    "    return int(cls), max(0,int(x1)), max(0,int(y1)), min(W-1,int(x2)), min(H-1,int(y2))\n",
    "\n",
    "print(\"\\n=== Amostras com caixas (até 3 do train) ===\")\n",
    "for img_path in train_imgs[:3]:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    W, H = img.size\n",
    "    lbl = (LABELS_DIR/\"train\"/f\"{img_path.stem}.txt\")\n",
    "    boxes = load_yolo_labels(lbl)\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for b in boxes:\n",
    "        _, x1, y1, x2, y2 = yolo_to_xyxy(b, W, H)\n",
    "        draw.rectangle([x1, y1, x2, y2], width=2)  # sem cor explícita (usa padrão)\n",
    "        draw.text((x1, max(0, y1-10)), \"muda\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{img_path.name} | {len(boxes)} caixas\")\n",
    "\n",
    "print(\"\\n[OK] Checagens concluídas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPA 5B — Treino YOLO 11 (detecção)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch, time, os\n",
    "from pathlib import Path\n",
    "\n",
    "# from ultralytics import settings\n",
    "# settings.update({\n",
    "#     \"runs_dir\": str(Path(\"../data/yolo\"))\n",
    "# })\n",
    "\n",
    "# Recomendo começar com o yolo11s; depois, se precisar de mais precisão, testar yolo11m\n",
    "MODEL_NAME = \"yolo11s.pt\"\n",
    "\n",
    "print(\"Carregando modelo base:\", MODEL_NAME)\n",
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "# Hiperparâmetros recomendados para mudas top-down\n",
    "train_args = dict(\n",
    "    data=str(DATA_YAML),\n",
    "    imgsz=1280,           # ajuda para objetos pequenos\n",
    "    epochs=100,\n",
    "    batch=-1,             # auto-batch\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "    workers=2,            # deixe 0 se tiver erro no Windows com multiprocess\n",
    "    patience=20,          # early stopping\n",
    "    cache=True,           # carrega imagens em RAM para acelerar\n",
    "    # Aumentações — leves e seguras para folhas\n",
    "    mosaic=0.05,          # reduz mosaico (0.0 para desativar)\n",
    "    mixup=0.0,            # desliga mixup\n",
    "    perspective=0.0,      # top-down: não distorcer perspectiva\n",
    "    flipud=0.0,           # não virar de cabeça para baixo\n",
    "    fliplr=0.5,           # ok inverter esquerda-direita\n",
    "    # Logs/plots\n",
    "    plots=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Parâmetros de treino ===\")\n",
    "for k,v in train_args.items():\n",
    "    print(f\"{k:>12}: {v}\")\n",
    "\n",
    "print(\"\\nIniciando treino...\")\n",
    "t0 = time.time()\n",
    "results = model.train(**train_args)\n",
    "t1 = time.time()\n",
    "print(f\"Treino finalizado em {t1 - t0:.1f}s (aprox).\")\n",
    "\n",
    "# Onde salvou?\n",
    "save_dir = None\n",
    "try:\n",
    "    save_dir = model.trainer.save_dir\n",
    "except Exception:\n",
    "    save_dir = getattr(results, \"save_dir\", None)\n",
    "\n",
    "print(\"save_dir:\", save_dir)\n",
    "if save_dir:\n",
    "    save_dir = Path(save_dir)\n",
    "    weights_dir = save_dir / \"weights\"\n",
    "    print(\"Pesos encontrados:\", list(weights_dir.glob(\"*.pt\")))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-deteccao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
